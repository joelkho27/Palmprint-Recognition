# Palmprint Recognition System# Palmprint_Recognition

This project is mainly to complete the palmprint feature extraction and classification tasks. The data set contains 99 people's palm print pictures, in which 3 palm print pictures of each person are distributed in the training set, and the other 3 palm print pictures are distributed in the test set. In this project, I tried the traditional method use SIFT to extract features and KNN for classification which get accuracy of 97.31%, and also tried the convolutional neural network method such as ResNet which get accuracy of 83.16%. In addition, I also tried to use the Gaussian filter, Gabor filter,etc. to process the palmprint image and extract the texture from the palmprint image, but these methods have not improved the accuracy of palmprint recognition.

A biometric authentication system using SIFT (Scale-Invariant Feature Transform) and CNN (Convolutional Neural Networks) for palmprint recognition.

## å‚è€ƒåšå®¢ï¼š

## ğŸ”‘ Features[ã€Pytorchã€‘ä½¿ç”¨ResNet-50è¿ç§»å­¦ä¹ è¿›è¡Œå›¾åƒåˆ†ç±»è®­ç»ƒ](https://blog.csdn.net/heiheiya/article/details/103028543)



- **SIFT-based Authentication**: Multi-layer validation system with feature matching[ã€pytorchã€‘æ•°æ®å¢å¼º](https://wizardforcel.gitbooks.io/learn-dl-with-pytorch-liaoxingyu/4.7.1.html)

- **CNN Implementation**: Deep learning approach using ResNet-18 with contrastive learning

- **6-Layer Validation**: SIFT + Texture + Geometric + Template + SSIM + Edge detection[opencv python SIFTï¼ˆå°ºåº¦ä¸å˜ç‰¹å¾å˜æ¢ï¼‰](https://segmentfault.com/a/1190000015709719)

- **Dataset Support**: Compatible with Tongji and PolyU palmprint databases

[OpenCV-Pythonæ•™ç¨‹:41.ç‰¹å¾åŒ¹é…](https://www.jianshu.com/p/ed57ee1056ab)

## ğŸ“ Project Structure

[opencv python ç‰¹å¾åŒ¹é…](https://segmentfault.com/a/1190000015735549)

```

â”œâ”€â”€ SIFT_DIP.py                 # Main SIFT implementation[opencvä¸­ cv2.KeyPointå’Œcv2.DMatchçš„ç†è§£](https://blog.csdn.net/qq_29023939/article/details/81130987)

â”œâ”€â”€ resnet18_DIP.py             # CNN ResNet-18 model

â”œâ”€â”€ texture_extraction_DIP.py   # Texture feature extraction[Kè¿‘é‚»ç®—æ³•](https://www.cnblogs.com/ybjourney/p/4702562.html)

â”œâ”€â”€ tongji_sift_auth.py         # SIFT authentication script
â”œâ”€â”€ tongji_cnn_trainer.py       # CNN training script
â”œâ”€â”€ tongji_dataset_prep.py      # Dataset preparation utilities
â”œâ”€â”€ palm_auth_ultimate_fixed.py # Complete authentication pipeline
â”œâ”€â”€ CNN_Partner/                # CNN partner implementation
â”œâ”€â”€ Palmprint/                  # Palmprint dataset
â””â”€â”€ Tongji_Palmprint/           # Tongji dataset
```

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- OpenCV
- NumPy
- PyTorch (for CNN)
- scikit-image

### Setup
```bash
# Install dependencies
pip install opencv-python numpy torch torchvision scikit-image pillow matplotlib
```

## ğŸ’» Usage

### SIFT Authentication
```python
python tongji_sift_auth.py
```

### CNN Training
```python
python tongji_cnn_trainer.py
```

### Dataset Preparation
```python
python tongji_dataset_prep.py
```

## ğŸ“Š Performance

### SIFT System
- **Accuracy**: 87.23%
- **GAR** (Genuine Accept Rate): 50.67%
- **FAR** (False Accept Rate): 0.45%
- **Processing Time**: ~0.5-1.0 seconds

### CNN System (ResNet-18)
- **Accuracy**: 91.68%
- **GAR**: 79.42%
- **FAR**: 1.21%
- **Processing Time**: ~0.12 seconds (GPU)

## ğŸ¯ Key Components

### SIFT Implementation
- Feature extraction with 1200 max features
- Lowe's ratio test (threshold: 0.75)
- Multi-layer validation for robustness

### CNN Implementation
- ResNet-18 architecture
- 256-D embeddings
- NT-Xent contrastive loss
- Cosine similarity matching (threshold: 0.8)

## ğŸ“š Dataset

Tested on:
- **Tongji Palmprint Database**: 50 individuals, 595 test comparisons
- **PolyU Palmprint Database**: Compatible

## ğŸ¤ Contributing

This project was developed as part of a Digital Image Processing course comparing traditional and deep learning approaches to palmprint recognition.

## ğŸ“„ License

This project is for educational purposes.
